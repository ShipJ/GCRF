''' Compute Introversion for each cell tower and normalise by the population of that region '''
# Input: ...
# Output: ...

import pandas as pd
import numpy as np
import sys

if __name__ == "__main__":

    # country = sys.argv[1]
    country = 'IvoryCoast'
    path = '/Users/JackShipway/Desktop/UCLProject/Data/%s' % country

    # Set known data set values (number of towers, and time length of data)
    if country == 'Senegal':
        num_bts, hours = 1668, 8760
    elif country == 'IvoryCoast':
        num_bts, hours = 1240, 3360
    else:
        num_bts, hours = 10000, 100000

    # Import adjacency matrix generated by adj_matrix.py
    adj_matrix = np.genfromtxt(path+'/CDR/staticmetrics/Other/adj_matrix.csv', delimiter=',')

    # Initialise introversion value for each cell tower
    introversion = np.zeros(num_bts)
    # Essentially the ratio of self-activity, to exterior-activity
    for i in range(num_bts):
        out = np.sum(np.delete(adj_matrix[i, :], i))
        introversion[i] = (adj_matrix[i, i] / out) if out > 0 else 0

    # Population of each voronoi section for normalisation, at each level of granularity
    IntersectPop = pd.DataFrame(pd.read_csv(path+'/Population/IntersectPop.csv'))
    adm_1_pop = IntersectPop.groupby('Adm_1')['Pop_2010'].sum().reset_index()
    adm_2_pop = IntersectPop.groupby('Adm_2')['Pop_2010'].sum().reset_index()
    adm_3_pop = IntersectPop.groupby('Adm_3')['Pop_2010'].sum().reset_index()
    adm_4_pop = IntersectPop.groupby('Adm_4')['Pop_2010'].sum().reset_index()

    # Remove non-existent values from both data sets
    cell_tower_adm = pd.DataFrame(pd.read_csv(path+'/CDR/celltowers/CDR_Adm_1234.csv'))
    list = np.array(cell_tower_adm['CellTowerID'])
    introversion = introversion[list]
    cell_tower_adm['introversion'] = introversion

    cell_towers_adm_1 = cell_tower_adm.groupby('ID_1')['ID_1'].count().reset_index(drop=True)
    cell_towers_adm_2 = cell_tower_adm.groupby('ID_2')['ID_2'].count().reset_index(drop=True)
    cell_towers_adm_3 = cell_tower_adm.groupby('ID_3')['ID_3'].count().reset_index(drop=True)
    cell_towers_adm_4 = cell_tower_adm.groupby('ID_4')['ID_4'].count().reset_index(drop=True)

    # Normalise final introversion values by population, at each level of granularity
    introversion_adm_1 = cell_tower_adm.groupby('ID_1')['introversion'].sum().reset_index()['introversion'] * (
        adm_1_pop['Pop_2010'] / cell_towers_adm_1)
    introversion_adm_2 = cell_tower_adm.groupby('ID_2')['introversion'].sum().reset_index()['introversion'] * (
        adm_2_pop['Pop_2010'] / cell_towers_adm_2)
    introversion_adm_3 = cell_tower_adm.groupby('ID_3')['introversion'].sum().reset_index()['introversion'] * (
        adm_3_pop['Pop_2010'] / cell_towers_adm_3)
    introversion_adm_4 = cell_tower_adm.groupby('ID_4')['introversion'].sum().reset_index()['introversion'] * (
        adm_4_pop['Pop_2010'] / cell_towers_adm_4)

    # np.savetxt(path+'/CDR/staticmetrics/Introversion/introversion_adm_1.csv', introversion_adm_1, delimiter=',')
    # np.savetxt(path+'/CDR/staticmetrics/Introversion/introversion_adm_2.csv', introversion_adm_2, delimiter=',')
    # np.savetxt(path+'/CDR/staticmetrics/Introversion/introversion_adm_3.csv', introversion_adm_3, delimiter=',')
    # np.savetxt(path+'/CDR/staticmetrics/Introversion/introversion_adm_4.csv', introversion_adm_4, delimiter=',')
